#! /usr/bin/env python
import cv2 as cv
import numpy as np
from scipy import ndimage

from skimage.segmentation import slic, mark_boundaries
from skimage.color import label2rgb

class ImagePreprocessing:

    """
    A Vortex NTNU Image Preprocessing implementation. Contains methods for pre-processing image data.
    
    Args: 
        clahe_cliplim: histogram clip-limit (tunable parameter) for the CLAHE method
        clahe_tilesize: size of the square kernels (tunable parameter) used when computing CLAHE

    """

    def __init__(self,
                clahe_cliplim,
                clahe_tilesize
                ):

            self.clahe = cv.createCLAHE(clipLimit=clahe_cliplim, tileGridSize=(clahe_tilesize,clahe_tilesize))


    def CLAHE(self, img):

        """
        Args:  
            img: image to be equalized with CLAHE method. Parameters for CLAHE are in the contructor for the class

        Returns: 
            equ: histogram equalized version of the image through CLAHE. Adaptive to gray-scale or 3 channel
        """

        equ = np.zeros(np.shape(img))
        
        if len(np.shape(img)) == 2: # If it is a grayscale/one channel image
            equ = self.clahe.apply(img)
            return equ
        elif len(np.shape(img)) < 2:
            raise IndexError("Image must be at least a 2D array")
        else:
            for i in range(np.shape(img)[2]):
                equ[:,:,i] = self.clahe.apply(img[:,:,i])
            return equ

    def SVD_compression(self, img, r):

        """
        Args:  
            img: image to be approximated with SVD
            r: truncation order for the SVD

        Returns: 
            An approximation of the image through SVD, up to the r-th singular value
        """
        U, S, VT = np.linalg.svd(img)
        return np.matmul(np.matmul(U[:,:r], np.diag(S)[:r, :r]), VT [:r, :])
    
    def central_difference(self, I, diff):
        """
        Computes the gradient in the x and y direction using
        a central difference filter, and returns the resulting
        gradient images (Ix, Iy) and the gradient magnitude Im.

        Do not use this implementation, use openCV one.
        #TODO: SHOULD WE REMOVE THIS ??
        """
        kernel = np.array([-diff, 0, diff])
        Ix = ndimage.convolve1d(I, kernel, axis=1)
        Iy = ndimage.convolve1d(I, kernel, axis=0)
        
        Im = np.sqrt(Ix ** 2 + Iy ** 2)
        return Ix, Iy, Im

    def gamma_correction(self, img, alpha, beta, gamma, ch=None, benG_single=None):

        """
        alpha-beta-gamma contrast correction for an image. The new image is computed after the model 
        
        I_new = gamma(alpha * I + beta), where gamma is a non-linear function, generated by look-up table to speed computations.

        Args:  
            img: image to be ran through the abg-contrasting scheme
            alpha: alpha parameter in the formula above
            beta: beta parameter in the formula above
            gamma: non-linear function of the pixel values. Computed in a look-up table
            ch: optional argument. Will return result on specified channel, either in RGB form or as a grayscale image depeding on
            the benG_single argument
            benG_single: TRUTH, but optional argument. Will return a single channel gray scale image. Only used if ch is also passed

        Returns: 
            new_img: result of the abg-contrasting scheme
        """

        look_up = np.empty((1,256), np.uint8)
        for i in range(256):
            look_up[0,i] = np.clip(pow(i / 255.0, gamma) * 255.0, 0, 255)


        if ch != None:
            new_img = (img[:,:,0] * alpha + np.full_like(img[:,:,0], beta)).astype(np.uint8)
            new_img = cv.LUT(new_img, look_up)
            if benG_single:
                return new_img.astype(float)
            else:
                img[:,:,ch] = new_img.astype(float)
                return img
        else:
            new_img = (img * alpha + np.full_like(img, beta)).astype(np.uint8)
            new_img = cv.LUT(new_img, look_up).astype(float)
            return new_img

    def gaussian_filter(self, img, sigma, ch=None):

        """
        Args:  
            img: image to be gaussian blurred
            sigma: variance of the gaussian filter
            ch: optional argument. If passed, only a single channel of the image will be blurred and returned as a gray

        Returns: 
            img_new: a gray world corrected image, where the channel intensities have been nomralized with the mean image
            intensities
        """

        K = int(round(2*np.pi*sigma) + 1)
        if K % 2 == 0:
            K += 1
        else:
            K = K
        if ch != None:
            return cv.GaussianBlur(img[:,:,ch], (K,K), sigma)
        else:
            return cv.GaussianBlur(img, (K,K), sigma)
    
    def gray_world(self, img):

        """
        Args:   
            img: image to be colour corrected through gray world method
        
        Returns: 
            img_new: a gray world corrected image, where the channel intensities have been nomralized with the mean image
            intensities
        """

        # 1) Calculate illuminant for each channel:     illu_channel = sum_channel / (nr_rows * nr_cols) (This is mean intensity of channel)
        # 2) Scale = (illum_red + illum_greed + illum_blue) / 3
        # 3) Correct each channel according to:     Img_chanel = Img_channel * scale / illuminant_channel (This is Ix * m)
        N = np.shape(img)[0]*np.shape(img)[1]
        img_new = np.empty_like(img)
        illum_red, illum_green, illum_blue = np.sum(img[:,:,2]) / N , np.sum(img[:,:,1]) / N, np.sum(img[:,:,0]) / N
        scale = (illum_red + illum_green + illum_blue) / 3

        img_new[:,:,0] = img[:,:,0] * scale / illum_blue
        img_new[:,:,1] = img[:,:,1] * scale / illum_green
        img_new[:,:,2] = img[:,:,2] * scale / illum_red
        return img_new

    def slic_colour_segmentation(self, img, num_segments, segment_compactness):

        """
        Args:   
            img: image to be SLIC segmented
            num_segmetns: number of superpixels to identify and segment the image into
            segment_compactness: parameter for the compactness of superpixels. Lower values produce images which are 
            closer to original. Higher values produce greater segmentation effect.
        
        Returns: 
            colour_segmented_img: an image with colour segmentation where superpixel clusters were identified

        """
        
        img_segments = slic(img, num_segments, compactness=segment_compactness)
        colour_segmented_img = label2rgb(img_segments, img, kind="avg").astype("float32")
        
        return colour_segmented_img

    def slic_contour_segmentation(self, img, num_segments, segment_compactness):
        """
        Args:   
            img: image to be SLIC segmented
            num_segmetns: number of superpixels to identify and segment the image into
            segment_compactness: parameter for the compactness of superpixels. Lower values produce images which are 
            closer to original. Higher values produce greater segmentation effect.
        
        Returns: 
            contour_segmented_img: an image with contours drawn where superpixel clusters were identified

        """
        
        img_segments = slic(img, num_segments, compactness=segment_compactness)
        contour_segmented_img = mark_boundaries(img, img_segments).astype("float32")
        
        return contour_segmented_img

    